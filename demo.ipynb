{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcd8ce2-97ed-4be7-822d-061a1dc50037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15682efc-2b63-4761-b3f3-6316649f8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"output_dir/google/mt5-base_tokenizer\", use_fast = True)\n",
    "\n",
    "pretrained_model = AutoModelForSeq2SeqLM.from_pretrained(\"output_dir/google/mt5-base_base_model_trained\")\n",
    "#custom_model = AutoModelForSeq2SeqLM.from_pretrained(\"output_dir/google/mt5-base_custom_model_trained.pt\")\n",
    "pretrained_model.eval();\n",
    "#custom_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "748680cc-31b7-4b4a-9661-5be5d1e3b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "  temp = tokenizer.encode(text, return_tensors=\"pt\", padding=True)\n",
    "  input_ids, att_mask = temp[\"input_ids\"], temp[\"attention_mask\"]\n",
    "  outputs1 = pretrained_model.generate(input_ids,\n",
    "                                      attention_mask=att_mask,\n",
    "                                      do_sample=False,\n",
    "                                      )\n",
    "  out1 = tokenizer.batch_decode(outputs1, skip_special_tokens=True)\n",
    "\n",
    "  #outputs2 = custom_model.generate(input_ids)\n",
    "  #out2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "  return out1 #out2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22c0f657-d987-41d6-9a38-60f208438a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869/\n",
      "Running on public URL: https://22372.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://22372.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efb2cf931d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/routes.py\", line 269, in predict\n",
      "    output = await run_in_threadpool(app.launchable.process_api, body, username)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/starlette/concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/to_thread.py\", line 29, in run_sync\n",
      "    limiter=limiter)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 573, in process_api\n",
      "    prediction, durations = self.process(raw_input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 616, in process\n",
      "    processed_input, return_duration=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 531, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"/tmp/ipykernel_32546/202747127.py\", line 3, in translate\n",
      "    input_ids, att_mask = temp[\"input_ids\"], temp[\"attention_mask\"]\n",
      "IndexError: too many indices for tensor of dimension 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/routes.py\", line 269, in predict\n",
      "    output = await run_in_threadpool(app.launchable.process_api, body, username)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/starlette/concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/to_thread.py\", line 29, in run_sync\n",
      "    limiter=limiter)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 573, in process_api\n",
      "    prediction, durations = self.process(raw_input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 616, in process\n",
      "    processed_input, return_duration=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 531, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"/tmp/ipykernel_32546/202747127.py\", line 3, in translate\n",
      "    input_ids, att_mask = temp[\"input_ids\"], temp[\"attention_mask\"]\n",
      "IndexError: too many indices for tensor of dimension 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/routes.py\", line 269, in predict\n",
      "    output = await run_in_threadpool(app.launchable.process_api, body, username)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/starlette/concurrency.py\", line 39, in run_in_threadpool\n",
      "    return await anyio.to_thread.run_sync(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/to_thread.py\", line 29, in run_sync\n",
      "    limiter=limiter)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 818, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/anyio/_backends/_asyncio.py\", line 754, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 573, in process_api\n",
      "    prediction, durations = self.process(raw_input)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 616, in process\n",
      "    processed_input, return_duration=True\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/gradio/interface.py\", line 531, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"/tmp/ipykernel_32546/202747127.py\", line 3, in translate\n",
      "    input_ids, att_mask = temp[\"input_ids\"], temp[\"attention_mask\"]\n",
      "IndexError: too many indices for tensor of dimension 2\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(fn=translate, inputs=\"text\", outputs=\"text\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb8e444-b622-483c-890a-2ddc244a41e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
